{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing library\n",
    "from apiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API key of youtube API\n",
    "api_key = 'AIzaSyBTEmbxj6cRWZauLgTB9MMb8XS48h_yjCs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Using YouTube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_name = input('Enter a channel name: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Getting channel id by its name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_id(channel_name):\n",
    "    result = youtube.search().list(q=channel_name, part='snippet', type='channel', maxResults=10).execute()\n",
    "    \n",
    "    channel_id = result['items'][0]['id']['channelId']\n",
    "    \n",
    "    return channel_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id = get_channel_id(channel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UCHdMK5Ef2El8KbD3L_WgANg'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Getting videos from the channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channel_videos(channel_id):\n",
    "    \n",
    "    # Get uploads playlist id\n",
    "    res = youtube.channels().list(id=channel_id, \n",
    "                                  part='contentDetails').execute()\n",
    "    playlist_id = res['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "    \n",
    "    videos = []\n",
    "    next_page_token = None\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        #Get the data for videos\n",
    "        results = youtube.playlistItems().list(playlistId=playlist_id, \n",
    "                                           part='snippet', \n",
    "                                           maxResults=50,\n",
    "                                           pageToken=next_page_token).execute()\n",
    "        videos += results['items']\n",
    "        \n",
    "        #If next page token is available, get the value or break the loop\n",
    "        next_page_token = results.get('nextPageToken')\n",
    "        \n",
    "        if next_page_token is None:\n",
    "            break\n",
    "    \n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = get_channel_videos(channel_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4070"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Getting statistics of videos of the channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_stats(video_ids):\n",
    "    stats = []\n",
    "    \n",
    "    #Extracting the information from videos\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        res = youtube.videos().list(id=','.join(video_ids[i:i+50]),\n",
    "                                   part='statistics').execute()\n",
    "        stats += res['items']\n",
    "        \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the video ids\n",
    "video_ids = list(map(lambda x:x['snippet']['resourceId']['videoId'], vids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the information\n",
    "stats = get_videos_stats(video_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Most Disliked videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_disliked = sorted(stats, key=lambda x:int(x['statistics']['dislikeCount']), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Id: be6t0_h8lks \n",
      "Number of Dislikes: 19420 \n",
      "\n",
      "Video Id: OB6_vByiBjo \n",
      "Number of Dislikes: 15676 \n",
      "\n",
      "Video Id: vjh9vBPycHA \n",
      "Number of Dislikes: 15438 \n",
      "\n",
      "Video Id: tTvmVC6Qv8A \n",
      "Number of Dislikes: 15372 \n",
      "\n",
      "Video Id: 9qzA4zw1Ypo \n",
      "Number of Dislikes: 15044 \n",
      "\n",
      "Video Id: yZhUnq-mB1w \n",
      "Number of Dislikes: 14643 \n",
      "\n",
      "Video Id: YUorphnx0Eg \n",
      "Number of Dislikes: 13524 \n",
      "\n",
      "Video Id: -d3IdvNLqdE \n",
      "Number of Dislikes: 13288 \n",
      "\n",
      "Video Id: Dijc507hn2k \n",
      "Number of Dislikes: 12920 \n",
      "\n",
      "Video Id: cjHsprfdQ-0 \n",
      "Number of Dislikes: 12675 \n",
      "\n",
      "Video Id: 0ZtJKvXSkFA \n",
      "Number of Dislikes: 11641 \n",
      "\n",
      "Video Id: 2DGB-NKwcgY \n",
      "Number of Dislikes: 11376 \n",
      "\n",
      "Video Id: 2wx9KQTSwK0 \n",
      "Number of Dislikes: 11236 \n",
      "\n",
      "Video Id: KzuNtozhTHg \n",
      "Number of Dislikes: 11210 \n",
      "\n",
      "Video Id: oZcf--g0b-4 \n",
      "Number of Dislikes: 11185 \n",
      "\n",
      "Video Id: 4_1ssSSH5sI \n",
      "Number of Dislikes: 11162 \n",
      "\n",
      "Video Id: NSIPUtlmHtM \n",
      "Number of Dislikes: 11139 \n",
      "\n",
      "Video Id: gdHgrK_BCCU \n",
      "Number of Dislikes: 10914 \n",
      "\n",
      "Video Id: 3vYO11myWmk \n",
      "Number of Dislikes: 10889 \n",
      "\n",
      "Video Id: b6Y4Ie2uBDw \n",
      "Number of Dislikes: 10636 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for video in most_disliked[:20]:\n",
    "    print('Video Id:', video['id'],'\\nNumber of Dislikes:', video['statistics']['dislikeCount'], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Most Liked Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_liked = sorted(stats, key=lambda x:int(x['statistics']['likeCount']), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Id: vjh9vBPycHA \n",
      "Number of Likes: 764090 \n",
      "\n",
      "Video Id: KzuNtozhTHg \n",
      "Number of Likes: 719571 \n",
      "\n",
      "Video Id: 4_1ssSSH5sI \n",
      "Number of Likes: 668259 \n",
      "\n",
      "Video Id: OB6_vByiBjo \n",
      "Number of Likes: 650947 \n",
      "\n",
      "Video Id: Dijc507hn2k \n",
      "Number of Likes: 634262 \n",
      "\n",
      "Video Id: TtfMEJ2j36Q \n",
      "Number of Likes: 508261 \n",
      "\n",
      "Video Id: mzPOQtUYmkI \n",
      "Number of Likes: 488031 \n",
      "\n",
      "Video Id: gdHgrK_BCCU \n",
      "Number of Likes: 484785 \n",
      "\n",
      "Video Id: b6Y4Ie2uBDw \n",
      "Number of Likes: 481895 \n",
      "\n",
      "Video Id: DZNE-cO-8g4 \n",
      "Number of Likes: 470343 \n",
      "\n",
      "Video Id: azLM-c2XnX8 \n",
      "Number of Likes: 465144 \n",
      "\n",
      "Video Id: 9WC91lrZas8 \n",
      "Number of Likes: 463015 \n",
      "\n",
      "Video Id: QgxnbXyz_V8 \n",
      "Number of Likes: 458650 \n",
      "\n",
      "Video Id: lguKPfzWDog \n",
      "Number of Likes: 458631 \n",
      "\n",
      "Video Id: oZcf--g0b-4 \n",
      "Number of Likes: 456771 \n",
      "\n",
      "Video Id: 2wx9KQTSwK0 \n",
      "Number of Likes: 449757 \n",
      "\n",
      "Video Id: gzJtJSxZGYI \n",
      "Number of Likes: 445049 \n",
      "\n",
      "Video Id: d9STzZDSck4 \n",
      "Number of Likes: 443279 \n",
      "\n",
      "Video Id: o07Ik1fOuSw \n",
      "Number of Likes: 421035 \n",
      "\n",
      "Video Id: tn67CoiKbDk \n",
      "Number of Likes: 409779 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for video in most_liked[:20]:\n",
    "    print('Video Id:', video['id'],'\\nNumber of Likes:', video['statistics']['likeCount'], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Most Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_views = sorted(stats, key=lambda x:int(x['statistics']['viewCount']), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Id: be6t0_h8lks \n",
      "Number of Views: 22249990 \n",
      "\n",
      "Video Id: tTvmVC6Qv8A \n",
      "Number of Views: 20163365 \n",
      "\n",
      "Video Id: xjMpPzPQuWw \n",
      "Number of Views: 14839332 \n",
      "\n",
      "Video Id: mff9Dv-MU8c \n",
      "Number of Views: 14170041 \n",
      "\n",
      "Video Id: 5TWfJkwBK4I \n",
      "Number of Views: 13371910 \n",
      "\n",
      "Video Id: epAu3EY8jOc \n",
      "Number of Views: 10938735 \n",
      "\n",
      "Video Id: b8SThXh0yPc \n",
      "Number of Views: 10806505 \n",
      "\n",
      "Video Id: kaEIY4S0z3o \n",
      "Number of Views: 10750756 \n",
      "\n",
      "Video Id: 4vpTF0-F-pA \n",
      "Number of Views: 10399417 \n",
      "\n",
      "Video Id: __l8oC8e0NM \n",
      "Number of Views: 10260860 \n",
      "\n",
      "Video Id: vjh9vBPycHA \n",
      "Number of Views: 10185337 \n",
      "\n",
      "Video Id: Dijc507hn2k \n",
      "Number of Views: 10029945 \n",
      "\n",
      "Video Id: uHbd4yOW_k0 \n",
      "Number of Views: 9468109 \n",
      "\n",
      "Video Id: H4ISzmu7K14 \n",
      "Number of Views: 9460261 \n",
      "\n",
      "Video Id: OB6_vByiBjo \n",
      "Number of Views: 9320303 \n",
      "\n",
      "Video Id: dgknhfO2T2Y \n",
      "Number of Views: 8551164 \n",
      "\n",
      "Video Id: 4_1ssSSH5sI \n",
      "Number of Views: 7989930 \n",
      "\n",
      "Video Id: etAzBxNczCA \n",
      "Number of Views: 7841545 \n",
      "\n",
      "Video Id: KzuNtozhTHg \n",
      "Number of Views: 7825138 \n",
      "\n",
      "Video Id: GJ4l4kUFMxw \n",
      "Number of Views: 7757772 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for video in most_views[:20]:\n",
    "    print('Video Id:', video['id'],'\\nNumber of Views:', video['statistics']['viewCount'], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Most Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_comments = sorted(stats, key=lambda x:int(x['statistics']['commentCount']), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Id: OB6_vByiBjo \n",
      "Number of Comments: 39323 \n",
      "\n",
      "Video Id: NSIPUtlmHtM \n",
      "Number of Comments: 36572 \n",
      "\n",
      "Video Id: agMGeqSef2k \n",
      "Number of Comments: 28571 \n",
      "\n",
      "Video Id: YUorphnx0Eg \n",
      "Number of Comments: 27910 \n",
      "\n",
      "Video Id: FLg68ALWZgA \n",
      "Number of Comments: 26543 \n",
      "\n",
      "Video Id: SNUi8RyxI7E \n",
      "Number of Comments: 26252 \n",
      "\n",
      "Video Id: lzSzYeuTW54 \n",
      "Number of Comments: 25869 \n",
      "\n",
      "Video Id: WeE3mxk_Eio \n",
      "Number of Comments: 23597 \n",
      "\n",
      "Video Id: HVwssNHvqZM \n",
      "Number of Comments: 21555 \n",
      "\n",
      "Video Id: DGBX-3uOF94 \n",
      "Number of Comments: 21495 \n",
      "\n",
      "Video Id: r6ME1b3pN7U \n",
      "Number of Comments: 20117 \n",
      "\n",
      "Video Id: haRU1jKOGig \n",
      "Number of Comments: 19955 \n",
      "\n",
      "Video Id: 7jz0P5IJpAA \n",
      "Number of Comments: 18846 \n",
      "\n",
      "Video Id: 2zjVyJGxjgs \n",
      "Number of Comments: 18494 \n",
      "\n",
      "Video Id: -8FC5WQ6pQo \n",
      "Number of Comments: 18372 \n",
      "\n",
      "Video Id: XSQmIVbpUtg \n",
      "Number of Comments: 18047 \n",
      "\n",
      "Video Id: 0ZtJKvXSkFA \n",
      "Number of Comments: 17976 \n",
      "\n",
      "Video Id: -MXjhKf-QDM \n",
      "Number of Comments: 17861 \n",
      "\n",
      "Video Id: HB7vapTmygQ \n",
      "Number of Comments: 17571 \n",
      "\n",
      "Video Id: 2DGB-NKwcgY \n",
      "Number of Comments: 16525 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for video in most_comments[:20]:\n",
    "    print('Video Id:', video['id'],'\\nNumber of Comments:', video['statistics']['commentCount'], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>After looking above:</h3>\n",
    "<h4>Highest number of dislikes - 19.5 K</h4>\n",
    "<h4>Highest number of likes - 76.5 K</h4>\n",
    "<h4>Highest number of views - 22.25 Million</h4>\n",
    "<h4>Highest number of comments - 39.30 K</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Vader Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 2.91% \n",
      "\n",
      "Using TextBlob Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 4.67% \n",
      "\n",
      "\n",
      "Detailed Report: \n",
      "10.00% people thought it was positive\n",
      "0.00% people thought it was weakly positive\n",
      "3.33% people thought it was strongly positive\n",
      "3.33% people thought it was negative\n",
      "0.00% people thought it was weakly negative\n",
      "3.33% people thought it was strongly negative\n",
      "80.00% people thought it was neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Vader Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 7.09% \n",
      "\n",
      "Using TextBlob Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 0.37% \n",
      "\n",
      "\n",
      "Detailed Report: \n",
      "10.00% people thought it was positive\n",
      "1.67% people thought it was weakly positive\n",
      "1.67% people thought it was strongly positive\n",
      "5.00% people thought it was negative\n",
      "0.00% people thought it was weakly negative\n",
      "3.33% people thought it was strongly negative\n",
      "76.67% people thought it was neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Vader Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 6.87% \n",
      "\n",
      "Using TextBlob Sentiment Analyzer: \n",
      "\n",
      "Overall Reviews are Negative with Score -0.02% \n",
      "\n",
      "\n",
      "Detailed Report: \n",
      "8.89% people thought it was positive\n",
      "2.22% people thought it was weakly positive\n",
      "1.11% people thought it was strongly positive\n",
      "4.44% people thought it was negative\n",
      "4.44% people thought it was weakly negative\n",
      "2.22% people thought it was strongly negative\n",
      "75.56% people thought it was neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Vader Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 5.90% \n",
      "\n",
      "Using TextBlob Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 1.94% \n",
      "\n",
      "\n",
      "Detailed Report: \n",
      "10.83% people thought it was positive\n",
      "3.33% people thought it was weakly positive\n",
      "1.67% people thought it was strongly positive\n",
      "4.17% people thought it was negative\n",
      "5.83% people thought it was weakly negative\n",
      "1.67% people thought it was strongly negative\n",
      "71.67% people thought it was neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Vader Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 8.41% \n",
      "\n",
      "Using TextBlob Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 2.35% \n",
      "\n",
      "\n",
      "Detailed Report: \n",
      "12.00% people thought it was positive\n",
      "3.33% people thought it was weakly positive\n",
      "2.67% people thought it was strongly positive\n",
      "4.00% people thought it was negative\n",
      "4.67% people thought it was weakly negative\n",
      "4.00% people thought it was strongly negative\n",
      "68.67% people thought it was neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Vader Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 7.45% \n",
      "\n",
      "Using TextBlob Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 0.11% \n",
      "\n",
      "\n",
      "Detailed Report: \n",
      "10.56% people thought it was positive\n",
      "3.33% people thought it was weakly positive\n",
      "2.22% people thought it was strongly positive\n",
      "5.56% people thought it was negative\n",
      "4.44% people thought it was weakly negative\n",
      "5.00% people thought it was strongly negative\n",
      "68.33% people thought it was neutral\n",
      "Using Vader Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 8.82% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TextBlob Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 1.41% \n",
      "\n",
      "\n",
      "Detailed Report: \n",
      "10.95% people thought it was positive\n",
      "2.86% people thought it was weakly positive\n",
      "2.86% people thought it was strongly positive\n",
      "4.76% people thought it was negative\n",
      "3.81% people thought it was weakly negative\n",
      "4.76% people thought it was strongly negative\n",
      "69.52% people thought it was neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Vader Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 8.19% \n",
      "\n",
      "Using TextBlob Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 1.49% \n",
      "\n",
      "\n",
      "Detailed Report: \n",
      "10.42% people thought it was positive\n",
      "2.92% people thought it was weakly positive\n",
      "2.92% people thought it was strongly positive\n",
      "5.42% people thought it was negative\n",
      "4.17% people thought it was weakly negative\n",
      "4.17% people thought it was strongly negative\n",
      "69.58% people thought it was neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Vader Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 7.82% \n",
      "\n",
      "Using TextBlob Sentiment Analyzer: \n",
      "\n",
      "Overall Reviews are Negative with Score -0.00% \n",
      "\n",
      "\n",
      "Detailed Report: \n",
      "9.26% people thought it was positive\n",
      "2.59% people thought it was weakly positive\n",
      "2.59% people thought it was strongly positive\n",
      "5.56% people thought it was negative\n",
      "4.07% people thought it was weakly negative\n",
      "5.19% people thought it was strongly negative\n",
      "70.37% people thought it was neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Vader Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 9.93% \n",
      "\n",
      "Using TextBlob Sentiment Analyzer: \n",
      "    Overall Reviews are Positive with Score 3.80% \n",
      "\n",
      "\n",
      "Detailed Report: \n",
      "9.33% people thought it was positive\n",
      "2.33% people thought it was weakly positive\n",
      "6.00% people thought it was strongly positive\n",
      "5.33% people thought it was negative\n",
      "4.33% people thought it was weakly negative\n",
      "4.67% people thought it was strongly negative\n",
      "67.67% people thought it was neutral\n"
     ]
    }
   ],
   "source": [
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "youtube = build(YOUTUBE_API_SERVICE_NAME,\n",
    "              YOUTUBE_API_VERSION,\n",
    "              developerKey=api_key)\n",
    "ucom = []\n",
    "def load_comments(match):\n",
    "    for item in match[\"items\"]:\n",
    "        comment = item[\"snippet\"][\"topLevelComment\"]\n",
    "        author = comment[\"snippet\"][\"authorDisplayName\"]\n",
    "        text = comment[\"snippet\"][\"textDisplay\"]\n",
    "#         print(\"Comment by user {}: {}\".format(author, text))\n",
    "        ucom.append(text)\n",
    "\n",
    "def get_comment_threads(youtube, video_id, limit):\n",
    "    results = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        maxResults=limit,\n",
    "        videoId=video_id,\n",
    "        textFormat=\"plainText\"\n",
    "    ).execute()\n",
    "    return results\n",
    "\n",
    "def get_comment_thread(youtube, video_id, mytoken, limit):\n",
    "    results = youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        maxResults=limit,\n",
    "        videoId=video_id,\n",
    "        textFormat=\"plainText\",\n",
    "        pageToken=mytoken\n",
    "    ).execute()\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for video in most_comments[:10]:\n",
    "    limit1 = 100\n",
    "    limit = 30\n",
    "    video_id = video['id']\n",
    "\n",
    "    if limit>100:\n",
    "      if limit%100==0:\n",
    "        count=limit/100-1\n",
    "      else:\n",
    "        count=limit/100\n",
    "    else:\n",
    "      count=0\n",
    "      limit1=limit\n",
    "\n",
    "    match = get_comment_threads(youtube, video_id, limit1)\n",
    "    next_page_token = match[\"nextPageToken\"]\n",
    "    load_comments(match)\n",
    "\n",
    "    while count>0:\n",
    "        if count==1:\n",
    "          match1 = get_comment_thread(youtube, video_id, next_page_token, (limit-(limit/100)*100))\n",
    "        else:    \n",
    "          match1 = get_comment_thread(youtube, video_id, next_page_token, 100)\n",
    "        next_page_token = match1[\"nextPageToken\"]\n",
    "        load_comments(match1)\n",
    "        count=count-1\n",
    "\n",
    "    #print(len(ucom))\n",
    "\n",
    "    import nltk \n",
    "    filtered_comments=[]\n",
    "    import re\n",
    "    def remove_emoji(string):\n",
    "        emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "        return emoji_pattern.sub(r'', string)\n",
    "\n",
    "    for comment in ucom:\n",
    "        com = remove_emoji(comment)\n",
    "        filtered_comments.append(com)\n",
    "    #print(filtered_comments)\n",
    "\n",
    "    #print(len(filtered_comments))\n",
    "\n",
    "    import emoji\n",
    "    import statistics\n",
    "    nltk.download('vader_lexicon')\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    sid=SentimentIntensityAnalyzer()\n",
    "\n",
    "    positive = 0\n",
    "    wpositive = 0\n",
    "    spositive = 0\n",
    "    negative = 0\n",
    "    wnegative = 0\n",
    "    snegative = 0\n",
    "    neutral = 0\n",
    "    track = []\n",
    "    for comment in filtered_comments:\n",
    "      i = sid.polarity_scores(comment)['compound']\n",
    "      if (i == 0):  \n",
    "            neutral += 1\n",
    "      elif (i > 0 and i <= 0.3):\n",
    "          wpositive += 1\n",
    "      elif (i > 0.3 and i <= 0.6):\n",
    "          positive += 1\n",
    "      elif (i > 0.6 and i <= 1):\n",
    "          spositive += 1\n",
    "      elif (i > -0.3 and i <= 0):\n",
    "          wnegative += 1\n",
    "      elif (i > -0.6 and i <= -0.3):\n",
    "          negative += 1\n",
    "      elif (i > -1 and i <= -0.6):\n",
    "          snegative += 1\n",
    "      track.append(i)\n",
    "\n",
    "\n",
    "\n",
    "    NoOfTerms = len(filtered_comments)\n",
    "\n",
    "\n",
    "    positive = format(100 * float(positive) / float(NoOfTerms), '0.2f')\n",
    "    wpositive = format(100 * float(wpositive) / float(NoOfTerms), '0.2f')\n",
    "    spositive = format(100 * float(spositive) / float(NoOfTerms), '0.2f')\n",
    "    negative = format(100 * float(negative) / float(NoOfTerms), '0.2f')\n",
    "    wnegative = format(100 * float(wnegative) / float(NoOfTerms), '0.2f')\n",
    "    snegative = format(100 * float(snegative) / float(NoOfTerms), '0.2f')\n",
    "    neutral = format(100 * float(neutral) / float(NoOfTerms), '0.2f')\n",
    "\n",
    "\n",
    "\n",
    "    Final_score = statistics.mean(track) \n",
    "\n",
    "    if Final_score>0:\n",
    "        print(\"Using Vader Sentiment Analyzer: \")\n",
    "        print(\"    Overall Reviews are Positive with Score \"+ str(format(100 * Final_score , '0.2f')+\"% \\n\"))\n",
    "    elif Final_score<0:\n",
    "        print(\"Using Vader Sentiment Analyzer: \\n\")\n",
    "        print(\"Overall Reviews are Negative with Score \"+ str(format(100 * Final_score , '0.2f')+\"% \\n\"))\n",
    "    else :\n",
    "        print(\"Using Vader Sentiment Analyzer: \\n\")\n",
    "        print(\"Overall Reviews are Moderate with Score \"+ str(format(100 * Final_score , '0.2f')+\"% \\n\"))\n",
    "\n",
    "\n",
    "    # print()\n",
    "    # print(\"Detailed Report: \")\n",
    "    # print(str(positive) + \"% people thought it was positive\")\n",
    "    # print(str(wpositive) + \"% people thought it was weakly positive\")\n",
    "    # print(str(spositive) + \"% people thought it was strongly positive\")\n",
    "    # print(str(negative) + \"% people thought it was negative\")\n",
    "    # print(str(wnegative) + \"% people thought it was weakly negative\")\n",
    "    # print(str(snegative) + \"% people thought it was strongly negative\")\n",
    "    # print(str(neutral) + \"% people thought it was neutral\")\n",
    "\n",
    "    from textblob import TextBlob\n",
    "\n",
    "    positive = 0\n",
    "    wpositive = 0\n",
    "    spositive = 0\n",
    "    negative = 0\n",
    "    wnegative = 0\n",
    "    snegative = 0\n",
    "    neutral = 0\n",
    "    track = []\n",
    "    for comment in filtered_comments:\n",
    "      analysis = TextBlob(comment)\n",
    "      i = analysis.sentiment.polarity\n",
    "      if (i == 0):  \n",
    "            neutral += 1\n",
    "      elif (i > 0 and i <= 0.3):\n",
    "          wpositive += 1\n",
    "      elif (i > 0.3 and i <= 0.6):\n",
    "          positive += 1\n",
    "      elif (i > 0.6 and i <= 1):\n",
    "          spositive += 1\n",
    "      elif (i > -0.3 and i <= 0):\n",
    "          wnegative += 1\n",
    "      elif (i > -0.6 and i <= -0.3):\n",
    "          negative += 1\n",
    "      elif (i > -1 and i <= -0.6):\n",
    "          snegative += 1\n",
    "      track.append(i)\n",
    "\n",
    "\n",
    "\n",
    "    NoOfTerms = len(filtered_comments)\n",
    "\n",
    "\n",
    "    positive = format(100 * float(positive) / float(NoOfTerms), '0.2f')\n",
    "    wpositive = format(100 * float(wpositive) / float(NoOfTerms), '0.2f')\n",
    "    spositive = format(100 * float(spositive) / float(NoOfTerms), '0.2f')\n",
    "    negative = format(100 * float(negative) / float(NoOfTerms), '0.2f')\n",
    "    wnegative = format(100 * float(wnegative) / float(NoOfTerms), '0.2f')\n",
    "    snegative = format(100 * float(snegative) / float(NoOfTerms), '0.2f')\n",
    "    neutral = format(100 * float(neutral) / float(NoOfTerms), '0.2f')\n",
    "\n",
    "\n",
    "\n",
    "    Final_score = statistics.mean(track) \n",
    "\n",
    "    if Final_score>0:\n",
    "        print(\"Using TextBlob Sentiment Analyzer: \")\n",
    "        print(\"    Overall Reviews are Positive with Score \"+ str(format(100 * Final_score , '0.2f')+\"% \\n\"))\n",
    "    elif Final_score<0:\n",
    "        print(\"Using TextBlob Sentiment Analyzer: \\n\")\n",
    "        print(\"Overall Reviews are Negative with Score \"+ str(format(100 * Final_score , '0.2f')+\"% \\n\"))\n",
    "    else :\n",
    "        print(\"Using TextBlob Sentiment Analyzer: \\n\")\n",
    "        print(\"Overall Reviews are Moderate with Score \"+ str(format(100 * Final_score , '0.2f')+\"% \\n\"))\n",
    "\n",
    "\n",
    "    print()\n",
    "    print(\"Detailed Report: \")\n",
    "    print(str(positive) + \"% people thought it was positive\")\n",
    "    print(str(wpositive) + \"% people thought it was weakly positive\")\n",
    "    print(str(spositive) + \"% people thought it was strongly positive\")\n",
    "    print(str(negative) + \"% people thought it was negative\")\n",
    "    print(str(wnegative) + \"% people thought it was weakly negative\")\n",
    "    print(str(snegative) + \"% people thought it was strongly negative\")\n",
    "    print(str(neutral) + \"% people thought it was neutral\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Drawing conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes = []\n",
    "dislikes = []\n",
    "comments = []\n",
    "views = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in most_disliked:\n",
    "    dislikes.append(int(video['statistics']['dislikeCount']))\n",
    "for video in most_liked:\n",
    "    likes.append(int(video['statistics']['likeCount']))\n",
    "for video in most_views:\n",
    "    views.append(int(video['statistics']['viewCount']))\n",
    "for video in most_comments:\n",
    "    comments.append(int(video['statistics']['commentCount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_likes = sum(likes)/len(likes)\n",
    "average_dislikes = sum(dislikes)/len(dislikes)\n",
    "average_comments = sum(comments)/len(comments)\n",
    "average_views = sum(views)/len(views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average likes on each video: 40279.05479115479\n",
      "Average dislikes on each video: 868.9235872235872\n",
      "Average comments on each video: 1165.2941031941032\n",
      "Average views on each video: 1175155.5823095823\n"
     ]
    }
   ],
   "source": [
    "print(f'Average likes on each video: {average_likes}')\n",
    "print(f'Average dislikes on each video: {average_dislikes}')\n",
    "print(f'Average comments on each video: {average_comments}')\n",
    "print(f'Average views on each video: {average_views}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "if average_likes > 40000 and average_dislikes < 1000 and average_comments > 1000 and average_views>1000000:\n",
    "    rating = 10\n",
    "elif average_likes > 35000 and average_dislikes < 1200 and average_comments > 800 and average_views >900000:\n",
    "    rating = 9\n",
    "elif average_likes > 30000 and average_dislikes < 1500 and average_comments > 600 and average_views >800000:\n",
    "    rating = 8\n",
    "elif average_likes > 25000 and average_dislikes < 1700 and average_comments > 400 and average_views >700000:\n",
    "    rating = 7\n",
    "elif average_likes > 20000 and average_dislikes < 2000 and average_comments > 300 and average_views >600000:\n",
    "    rating = 6\n",
    "elif average_likes > 15000 and average_dislikes < 2200 and average_comments > 250 and average_views >500000:\n",
    "    rating = 5\n",
    "elif average_likes > 10000 and average_dislikes < 2400 and average_comments > 200 and average_views >400000:\n",
    "    rating = 4\n",
    "elif average_likes > 7500 and average_dislikes < 2500 and average_comments > 150 and average_views >300000:\n",
    "    rating = 3\n",
    "elif average_likes > 5000 and average_dislikes < 2750 and average_comments > 100 and average_views >200000:\n",
    "    rating = 2\n",
    "elif average_likes > 100 and average_dislikes < 3000 and average_comments > 50 and average_views >1000:\n",
    "    rating = 1\n",
    "else:\n",
    "    rating = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
